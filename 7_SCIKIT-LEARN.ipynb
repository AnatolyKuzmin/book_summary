{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d4d48c-748e-4c10-a4c1-d3b90d6d099b",
   "metadata": {},
   "source": [
    "# 7_SCIKIT-LEARN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1c4b6b-aa4a-4539-8677-1758a87913fd",
   "metadata": {},
   "source": [
    "## 7.1. Основы работы с классами, строящими модели предварительной подготовки данных и модели машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1baae0-3245-4e7e-b63b-601c7c17e410",
   "metadata": {},
   "source": [
    "Scikit-learn использует объектно-ориентированный подход, где каждая модель — это класс с определенными методами. Давайте разберемся, как это работает.\n",
    "\n",
    "**Классификаторы vs Регрессоры**  \n",
    "- Классификаторы: `[Метод]Classifier` (например, `RandomForestClassifier`)\n",
    "- Регрессоры: `[Метод]Regressor` (например, `LinearRegression`)\n",
    "- Универсальные: `[Метод]` (например, `KMeans` для кластеризации)\n",
    "\n",
    "Ключевые принципы\n",
    "1. Единообразие интерфейса: Все модели имеют методы .fit(), .predict()\n",
    "2. Независимость от типа данных: Работают с NumPy arrays и pandas DataFrames\n",
    "3. Совместимость: Можно комбинировать в конвейерах (pipelines)\n",
    "4. Наследование: Используйте BaseEstimator и TransformerMixin для совместимости\n",
    "\n",
    "Важные методы\n",
    "|Метод|Назначение|Возвращает|\n",
    "|-|-|-|\n",
    "|`.fit()`|Обучение модели|`self`|\n",
    "|`.predict()`|Предсказания|Массив предсказаний|\n",
    "|`.transform()`|Преобразование данных|Преобразованные данные|\n",
    "|`.fit_transform()`|Обучение + преобразование|Преобразованные данные|\n",
    "|`.score()`|Оценка качества|Значение метрики|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b9bf6b-9a4b-439c-b9b0-009c1a81790a",
   "metadata": {},
   "source": [
    "**Стандартный workflow в scikit-learn**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b7defd-90c6-4c24-8114-da33401197a0",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Создание экземпляра класса\n",
    "model = RandomForestClassifier()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 2. Обучение модели\n",
    "scaler.fit(X_train)          # Только признаки\n",
    "model.fit(X_train, y_train)  # Признаки + метки\n",
    "\n",
    "# 3. Применение модели\n",
    "X_scaled = scaler.transform(X_test)\n",
    "predictions = model.predict(X_scaled)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de8dc0b-5051-4354-874f-8be538f77413",
   "metadata": {},
   "source": [
    "**Создание собственного класса преобразователя**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb202605-19ad-4319-91b2-6b8be6fbdeae",
   "metadata": {},
   "source": [
    "```python\n",
    "# Базовый шаблон\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, param1=default_value):\n",
    "        self.param1 = param1\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Вычисление параметров\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Применение преобразования\n",
    "        return X\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8c895f-2483-41a7-81b4-6e8bdd3037ef",
   "metadata": {},
   "source": [
    "**Пример: Замена пропусков средним (MeanImputer)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa925bf-3255-4aba-86c6-55c9241e45bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class MeanImputer:\n",
    "    def __init__(self, copy=True):\n",
    "        self.copy = copy\n",
    "        self._encoder_dict = {}\n",
    "    \n",
    "    def _is_numpy(self, X):\n",
    "        return isinstance(X, np.ndarray)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Создаем словарь для хранения средних значений\n",
    "        self._encoder_dict = {}\n",
    "        \n",
    "        # Проверяем тип данных\n",
    "        is_np = self._is_numpy(X)\n",
    "        \n",
    "        # Обработка 1D массива\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        \n",
    "        # Вычисляем средние значения\n",
    "        if is_np:\n",
    "            for col in range(X.shape[1]):\n",
    "                self._encoder_dict[col] = np.nanmean(X[:, col])\n",
    "        else:\n",
    "            for col in X.columns:\n",
    "                self._encoder_dict[col] = X[col].mean()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.copy:\n",
    "            X = X.copy()\n",
    "        \n",
    "        is_np = self._is_numpy(X)\n",
    "        \n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        \n",
    "        # Замена пропусков\n",
    "        if is_np:\n",
    "            for col in range(X.shape[1]):\n",
    "                X[:, col] = np.nan_to_num(X[:, col], nan=self._encoder_dict[col])\n",
    "        else:\n",
    "            for col in X.columns:\n",
    "                X[col] = np.where(X[col].isnull(), self._encoder_dict[col], X[col])\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661b6366-db59-41f6-8d48-a557bd7f9062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Balance        Age\n",
      "0      8.3  23.000000\n",
      "1      7.2  29.000000\n",
      "2     10.2  36.000000\n",
      "3      3.1  29.333333\n"
     ]
    }
   ],
   "source": [
    "# Использование MeanImputer\n",
    "\n",
    "# Пример с DataFrame\n",
    "toy_train = pd.DataFrame({\n",
    "    'Balance': [8.3, np.nan, 10.2, 3.1],\n",
    "    'Age': [23, 29, 36, np.nan]\n",
    "})\n",
    "\n",
    "# Создание и применение преобразователя\n",
    "imp = MeanImputer()\n",
    "imp.fit(toy_train)\n",
    "toy_train_inputed = imp.transform(toy_train)\n",
    "print(toy_train_inputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ba164b-d0ef-4356-82a4-69a53d1b6587",
   "metadata": {},
   "source": [
    "**Создание собственной модели машинного обучения**\n",
    "\n",
    "Пример: K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14a1f47-0f2b-4a16-b69c-ba143770c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class KNN_Estimator:\n",
    "    def __init__(self, k=5, task='classification'):\n",
    "        self.k = k\n",
    "        self.task = task\n",
    "    \n",
    "    def _euclidean_distance(self, x1, x2):\n",
    "        \"\"\"Вычисляет евклидово расстояние между двумя точками\"\"\"\n",
    "        distance = 0\n",
    "        for i in range(len(x1)):\n",
    "            distance += (x1[i] - x2[i]) ** 2\n",
    "        return math.sqrt(distance)\n",
    "    \n",
    "    def _vote(self, neighbor_labels):\n",
    "        \"\"\"Голосование для классификации\"\"\"\n",
    "        counts = np.bincount(neighbor_labels.astype('int'))\n",
    "        return counts.argmax()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Запоминаем обучающие данные\"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказание для новых данных\"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        for test_sample in X:\n",
    "            # Находим расстояния до всех точек\n",
    "            distances = [self._euclidean_distance(test_sample, x) \n",
    "                        for x in self.X_train]\n",
    "            \n",
    "            # Находим k ближайших соседей\n",
    "            nearest_indices = np.argsort(distances)[:self.k]\n",
    "            nearest_labels = self.y_train[nearest_indices]\n",
    "            \n",
    "            if self.task == 'classification':\n",
    "                # Голосование для классификации\n",
    "                pred = self._vote(nearest_labels)\n",
    "            else:\n",
    "                # Среднее для регрессии\n",
    "                pred = np.mean(nearest_labels)\n",
    "            \n",
    "            predictions.append(pred)\n",
    "        \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e899faf3-7c7e-4a53-a04e-a1a3082d5d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказание: [0]\n"
     ]
    }
   ],
   "source": [
    "# Использование KNN модели\n",
    "\n",
    "# Данные для классификации\n",
    "X_train = np.array([[1, 2], [2, 3], [3, 1], [4, 2]])\n",
    "y_train = np.array([0, 0, 1, 1])\n",
    "\n",
    "X_test = np.array([[2.5, 2]])\n",
    "\n",
    "# Обучение и предсказание\n",
    "knn = KNN_Estimator(k=3, task='classification')\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "print(f\"Предсказание: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f80a53-bfea-43f9-a629-07a4ef3c9360",
   "metadata": {},
   "source": [
    "## 7.2. Строим свой первый конвейер моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21e38c0-151b-4689-8ff3-986bd1ed96b6",
   "metadata": {},
   "source": [
    "**Конвейер (pipeline)** — это способ объединить несколько шагов обработки данных и моделирования в одну последовательность. Представьте, что это конвейер на заводе, где данные проходят несколько станций обработки перед тем как стать готовым продуктом (моделью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3be8cdc-1a28-4ba1-a520-9bcc39396f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки pandas, numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# импортируем модуль os и функцию train_test_split()\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "# импортируем класс StandardScaler,\n",
    "# выполняющий стандартизацию\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# импортируем класс LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb901d0e-226b-4c3f-8c75-a511550aa3ce",
   "metadata": {},
   "source": [
    "```python\n",
    "# взглянем на наш рабочий каталог\n",
    "os.getcwd()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1137869-77b7-48b5-a01a-33695f074a66",
   "metadata": {},
   "source": [
    "**Ключевые правила**\n",
    "\n",
    "- Сначала разделяй, потом обрабатывай — избегай утечки данных\n",
    "- Обучай преобразования только на обучающих данных — тестовые данные должны быть \"невидимы\"\n",
    "- Используй конвейеры — для удобства и предотвращения ошибок\n",
    "- Настраивай гиперпараметры на валидационной выборке — тестовая только для финальной оценки\n",
    "- Интерпретируй коэффициенты после стандартизации — они показывают влияние в стандартных отклонениях\n",
    "\n",
    "Конвейер — это как рецепт: все ингредиенты обрабатываются в правильной последовательности, чтобы получить вкусный результат! 🚀🍳"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7466a194-423a-4c8d-ade1-c3d8dc62e775",
   "metadata": {},
   "source": [
    "**Зачем нужен конвейер?**\n",
    "\n",
    "Без конвейера:\n",
    "```python\n",
    "# 1. Стандартизируем данные\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 2. Обучаем модель\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 3. Делаем прогноз\n",
    "predictions = model.predict(X_test_scaled)\n",
    "```\n",
    "С конвейером:\n",
    "\n",
    "```python\n",
    "# Все в одной строке!\n",
    "pipeline = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "pipeline.fit(X_train, y_train)\n",
    "predictions = pipeline.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e8b216-c9e5-488c-a3c5-4cd161833ad3",
   "metadata": {},
   "source": [
    "**Основные проблемы без конвейера**\n",
    "\n",
    "Утечка данных (data leakage)\n",
    "Если сначала обработать ВСЕ данные, а потом разделить на обучающую/тестовую выборки, модель \"узнает\" о тестовых данных заранее:\n",
    "\n",
    "```python\n",
    "# ❌ НЕПРАВИЛЬНО: утечка данных\n",
    "scaler = StandardScaler()\n",
    "X_all_scaled = scaler.fit_transform(X_all)  # Обрабатываем все данные\n",
    "X_train, X_test = train_test_split(X_all_scaled)  # Потом делим\n",
    "\n",
    "# ✅ ПРАВИЛЬНО: сначала делим, потом обрабатываем\n",
    "X_train, X_test = train_test_split(X_all)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Только на обучающих!\n",
    "X_test_scaled = scaler.transform(X_test)        # Применяем параметры с обучения\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af6382-5238-455b-ac65-e4f925fa0b36",
   "metadata": {},
   "source": [
    "**Разбиение данных на выборки**\n",
    "\n",
    "Три типа выборок:\n",
    "- Обучающая — для обучения модели\n",
    "- Валидационная — для настройки гиперпараметров\n",
    "- Тестовая — для финальной оценки\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Разделяем данные\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('Response', axis=1),  # Признаки (без целевой переменной)\n",
    "    data['Response'],               # Целевая переменная\n",
    "    test_size=0.3,                  # 30% в тестовую выборку\n",
    "    stratify=data['Response'],      # Сохраняем пропорции классов\n",
    "    random_state=42                 # Для воспроизводимости\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b596ebed-1688-48cd-863d-6cea0f7c693a",
   "metadata": {},
   "source": [
    "**Параметры vs Гиперпараметры**\n",
    "\n",
    "Параметры — то, что модель \"учит\" сама:  \n",
    "📊 Средние значения для заполнения пропусков  \n",
    "📈 Регрессионные коэффициенты в логистической регрессии  \n",
    "🌳 Правила разбиения в дереве решений\n",
    "\n",
    "Гиперпараметры — то, что задаем МЫ:  \n",
    "🔢 Количество соседей в KNN (k=5)  \n",
    "💪 Сила регуляризации в логистической регрессии (C=10)  \n",
    "🎯 Максимальная глубина дерева (max_depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb83e7-21e2-407a-8ec5-69a82b584d39",
   "metadata": {},
   "source": [
    "**Стандартизация данных**\n",
    "\n",
    "Зачем нужна? Чтобы признаки были в одном масштабе:\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Создаем и обучаем scaler ТОЛЬКО на обучающих данных\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # Вычисляем средние и стандартные отклонения\n",
    "\n",
    "# Применяем к обеим выборкам\n",
    "X_train_scaled = scaler.transform(X_train)  # Обучающая\n",
    "X_test_scaled = scaler.transform(X_test)    # Тестовая (те же параметры!)\n",
    "```\n",
    "\n",
    "Формула стандартизации:\n",
    "\n",
    "```text\n",
    "x_стандартизированный = (x - среднее) / стандартное_отклонение\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248819f0-627b-47da-ac20-7a66a9d37ced",
   "metadata": {},
   "source": [
    "**Обучение модели**\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Создаем и обучаем модель\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=200)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Оцениваем качество\n",
    "train_score = model.score(X_train_scaled, y_train)\n",
    "test_score = model.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"Качество на обучении: {train_score:.3f}\")\n",
    "print(f\"Качество на тесте: {test_score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
