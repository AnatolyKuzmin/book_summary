{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d4d48c-748e-4c10-a4c1-d3b90d6d099b",
   "metadata": {},
   "source": [
    "# 7_SCIKIT-LEARN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1c4b6b-aa4a-4539-8677-1758a87913fd",
   "metadata": {},
   "source": [
    "## 7.1. –û—Å–Ω–æ–≤—ã —Ä–∞–±–æ—Ç—ã —Å –∫–ª–∞—Å—Å–∞–º–∏, —Å—Ç—Ä–æ—è—â–∏–º–∏ –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1baae0-3245-4e7e-b63b-601c7c17e410",
   "metadata": {},
   "source": [
    "Scikit-learn –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—ä–µ–∫—Ç–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥, –≥–¥–µ –∫–∞–∂–¥–∞—è –º–æ–¥–µ–ª—å ‚Äî —ç—Ç–æ –∫–ª–∞—Å—Å —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏. –î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º—Å—è, –∫–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç.\n",
    "\n",
    "**–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã vs –†–µ–≥—Ä–µ—Å—Å–æ—Ä—ã**  \n",
    "- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã: `[–ú–µ—Ç–æ–¥]Classifier` (–Ω–∞–ø—Ä–∏–º–µ—Ä, `RandomForestClassifier`)\n",
    "- –†–µ–≥—Ä–µ—Å—Å–æ—Ä—ã: `[–ú–µ—Ç–æ–¥]Regressor` (–Ω–∞–ø—Ä–∏–º–µ—Ä, `LinearRegression`)\n",
    "- –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ: `[–ú–µ—Ç–æ–¥]` (–Ω–∞–ø—Ä–∏–º–µ—Ä, `KMeans` –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏)\n",
    "\n",
    "–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã\n",
    "1. –ï–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞: –í—Å–µ –º–æ–¥–µ–ª–∏ –∏–º–µ—é—Ç –º–µ—Ç–æ–¥—ã .fit(), .predict()\n",
    "2. –ù–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö: –†–∞–±–æ—Ç–∞—é—Ç —Å NumPy arrays –∏ pandas DataFrames\n",
    "3. –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å: –ú–æ–∂–Ω–æ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å –≤ –∫–æ–Ω–≤–µ–π–µ—Ä–∞—Ö (pipelines)\n",
    "4. –ù–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ BaseEstimator –∏ TransformerMixin –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏\n",
    "\n",
    "–í–∞–∂–Ω—ã–µ –º–µ—Ç–æ–¥—ã\n",
    "|–ú–µ—Ç–æ–¥|–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ|–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç|\n",
    "|-|-|-|\n",
    "|`.fit()`|–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏|`self`|\n",
    "|`.predict()`|–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è|–ú–∞—Å—Å–∏–≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π|\n",
    "|`.transform()`|–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö|–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ|\n",
    "|`.fit_transform()`|–û–±—É—á–µ–Ω–∏–µ + –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ|–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ|\n",
    "|`.score()`|–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞|–ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b9bf6b-9a4b-439c-b9b0-009c1a81790a",
   "metadata": {},
   "source": [
    "**–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π workflow –≤ scikit-learn**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b7defd-90c6-4c24-8114-da33401197a0",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –∫–ª–∞—Å—Å–∞\n",
    "model = RandomForestClassifier()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 2. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "scaler.fit(X_train)          # –¢–æ–ª—å–∫–æ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "model.fit(X_train, y_train)  # –ü—Ä–∏–∑–Ω–∞–∫–∏ + –º–µ—Ç–∫–∏\n",
    "\n",
    "# 3. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "X_scaled = scaler.transform(X_test)\n",
    "predictions = model.predict(X_scaled)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de8dc0b-5051-4354-874f-8be538f77413",
   "metadata": {},
   "source": [
    "**–°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—è**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb202605-19ad-4319-91b2-6b8be6fbdeae",
   "metadata": {},
   "source": [
    "```python\n",
    "# –ë–∞–∑–æ–≤—ã–π —à–∞–±–ª–æ–Ω\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, param1=default_value):\n",
    "        self.param1 = param1\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\n",
    "        return X\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8c895f-2483-41a7-81b4-6e8bdd3037ef",
   "metadata": {},
   "source": [
    "**–ü—Ä–∏–º–µ—Ä: –ó–∞–º–µ–Ω–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ —Å—Ä–µ–¥–Ω–∏–º (MeanImputer)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa925bf-3255-4aba-86c6-55c9241e45bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class MeanImputer:\n",
    "    def __init__(self, copy=True):\n",
    "        self.copy = copy\n",
    "        self._encoder_dict = {}\n",
    "    \n",
    "    def _is_numpy(self, X):\n",
    "        return isinstance(X, np.ndarray)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "        self._encoder_dict = {}\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö\n",
    "        is_np = self._is_numpy(X)\n",
    "        \n",
    "        # –û–±—Ä–∞–±–æ—Ç–∫–∞ 1D –º–∞—Å—Å–∏–≤–∞\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        \n",
    "        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "        if is_np:\n",
    "            for col in range(X.shape[1]):\n",
    "                self._encoder_dict[col] = np.nanmean(X[:, col])\n",
    "        else:\n",
    "            for col in X.columns:\n",
    "                self._encoder_dict[col] = X[col].mean()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.copy:\n",
    "            X = X.copy()\n",
    "        \n",
    "        is_np = self._is_numpy(X)\n",
    "        \n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "        \n",
    "        # –ó–∞–º–µ–Ω–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤\n",
    "        if is_np:\n",
    "            for col in range(X.shape[1]):\n",
    "                X[:, col] = np.nan_to_num(X[:, col], nan=self._encoder_dict[col])\n",
    "        else:\n",
    "            for col in X.columns:\n",
    "                X[col] = np.where(X[col].isnull(), self._encoder_dict[col], X[col])\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661b6366-db59-41f6-8d48-a557bd7f9062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Balance        Age\n",
      "0      8.3  23.000000\n",
      "1      7.2  29.000000\n",
      "2     10.2  36.000000\n",
      "3      3.1  29.333333\n"
     ]
    }
   ],
   "source": [
    "# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ MeanImputer\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä —Å DataFrame\n",
    "toy_train = pd.DataFrame({\n",
    "    'Balance': [8.3, np.nan, 10.2, 3.1],\n",
    "    'Age': [23, 29, 36, np.nan]\n",
    "})\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "imp = MeanImputer()\n",
    "imp.fit(toy_train)\n",
    "toy_train_inputed = imp.transform(toy_train)\n",
    "print(toy_train_inputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ba164b-d0ef-4356-82a4-69a53d1b6587",
   "metadata": {},
   "source": [
    "**–°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è**\n",
    "\n",
    "–ü—Ä–∏–º–µ—Ä: K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14a1f47-0f2b-4a16-b69c-ba143770c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class KNN_Estimator:\n",
    "    def __init__(self, k=5, task='classification'):\n",
    "        self.k = k\n",
    "        self.task = task\n",
    "    \n",
    "    def _euclidean_distance(self, x1, x2):\n",
    "        \"\"\"–í—ã—á–∏—Å–ª—è–µ—Ç –µ–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–æ—á–∫–∞–º–∏\"\"\"\n",
    "        distance = 0\n",
    "        for i in range(len(x1)):\n",
    "            distance += (x1[i] - x2[i]) ** 2\n",
    "        return math.sqrt(distance)\n",
    "    \n",
    "    def _vote(self, neighbor_labels):\n",
    "        \"\"\"–ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\"\"\"\n",
    "        counts = np.bincount(neighbor_labels.astype('int'))\n",
    "        return counts.argmax()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"–ó–∞–ø–æ–º–∏–Ω–∞–µ–º –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ\"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        for test_sample in X:\n",
    "            # –ù–∞—Ö–æ–¥–∏–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–æ –≤—Å–µ—Ö —Ç–æ—á–µ–∫\n",
    "            distances = [self._euclidean_distance(test_sample, x) \n",
    "                        for x in self.X_train]\n",
    "            \n",
    "            # –ù–∞—Ö–æ–¥–∏–º k –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π\n",
    "            nearest_indices = np.argsort(distances)[:self.k]\n",
    "            nearest_labels = self.y_train[nearest_indices]\n",
    "            \n",
    "            if self.task == 'classification':\n",
    "                # –ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "                pred = self._vote(nearest_labels)\n",
    "            else:\n",
    "                # –°—Ä–µ–¥–Ω–µ–µ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "                pred = np.mean(nearest_labels)\n",
    "            \n",
    "            predictions.append(pred)\n",
    "        \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e899faf3-7c7e-4a53-a04e-a1a3082d5d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: [0]\n"
     ]
    }
   ],
   "source": [
    "# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ KNN –º–æ–¥–µ–ª–∏\n",
    "\n",
    "# –î–∞–Ω–Ω—ã–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "X_train = np.array([[1, 2], [2, 3], [3, 1], [4, 2]])\n",
    "y_train = np.array([0, 0, 1, 1])\n",
    "\n",
    "X_test = np.array([[2.5, 2]])\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "knn = KNN_Estimator(k=3, task='classification')\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "print(f\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f80a53-bfea-43f9-a629-07a4ef3c9360",
   "metadata": {},
   "source": [
    "## 7.2. –°—Ç—Ä–æ–∏–º —Å–≤–æ–π –ø–µ—Ä–≤—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä –º–æ–¥–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21e38c0-151b-4689-8ff3-986bd1ed96b6",
   "metadata": {},
   "source": [
    "**–ö–æ–Ω–≤–µ–π–µ—Ä (pipeline)** ‚Äî —ç—Ç–æ —Å–ø–æ—Å–æ–± –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤ –æ–¥–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å. –ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ, —á—Ç–æ —ç—Ç–æ –∫–æ–Ω–≤–µ–π–µ—Ä –Ω–∞ –∑–∞–≤–æ–¥–µ, –≥–¥–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ö–æ–¥—è—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç–∞–Ω—Ü–∏–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–µ—Ä–µ–¥ —Ç–µ–º –∫–∞–∫ —Å—Ç–∞—Ç—å –≥–æ—Ç–æ–≤—ã–º –ø—Ä–æ–¥—É–∫—Ç–æ–º (–º–æ–¥–µ–ª—å—é)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3be8cdc-1a28-4ba1-a520-9bcc39396f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ pandas, numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å os –∏ —Ñ—É–Ω–∫—Ü–∏—é train_test_split()\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "# –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å StandardScaler,\n",
    "# –≤—ã–ø–æ–ª–Ω—è—é—â–∏–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—é\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb901d0e-226b-4c3f-8c75-a511550aa3ce",
   "metadata": {},
   "source": [
    "```python\n",
    "# –≤–∑–≥–ª—è–Ω–µ–º –Ω–∞ –Ω–∞—à —Ä–∞–±–æ—á–∏–π –∫–∞—Ç–∞–ª–æ–≥\n",
    "os.getcwd()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1137869-77b7-48b5-a01a-33695f074a66",
   "metadata": {},
   "source": [
    "**–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∞–≤–∏–ª–∞**\n",
    "\n",
    "- –°–Ω–∞—á–∞–ª–∞ —Ä–∞–∑–¥–µ–ª—è–π, –ø–æ—Ç–æ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–π ‚Äî –∏–∑–±–µ–≥–∞–π —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
    "- –û–±—É—á–∞–π –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–æ–ª—å–∫–æ –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö ‚Äî —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å \"–Ω–µ–≤–∏–¥–∏–º—ã\"\n",
    "- –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω–≤–µ–π–µ—Ä—ã ‚Äî –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –∏ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –æ—à–∏–±–æ–∫\n",
    "- –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–π –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ ‚Äî —Ç–µ—Å—Ç–æ–≤–∞—è —Ç–æ–ª—å–∫–æ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏\n",
    "- –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –ø–æ—Å–ª–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏ ‚Äî –æ–Ω–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –≤–ª–∏—è–Ω–∏–µ –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è—Ö\n",
    "\n",
    "–ö–æ–Ω–≤–µ–π–µ—Ä ‚Äî —ç—Ç–æ –∫–∞–∫ —Ä–µ—Ü–µ–ø—Ç: –≤—Å–µ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –≤–∫—É—Å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! üöÄüç≥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7466a194-423a-4c8d-ade1-c3d8dc62e775",
   "metadata": {},
   "source": [
    "**–ó–∞—á–µ–º –Ω—É–∂–µ–Ω –∫–æ–Ω–≤–µ–π–µ—Ä?**\n",
    "\n",
    "–ë–µ–∑ –∫–æ–Ω–≤–µ–π–µ—Ä–∞:\n",
    "```python\n",
    "# 1. –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 2. –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 3. –î–µ–ª–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑\n",
    "predictions = model.predict(X_test_scaled)\n",
    "```\n",
    "–° –∫–æ–Ω–≤–µ–π–µ—Ä–æ–º:\n",
    "\n",
    "```python\n",
    "# –í—Å–µ –≤ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ!\n",
    "pipeline = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "pipeline.fit(X_train, y_train)\n",
    "predictions = pipeline.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e8b216-c9e5-488c-a3c5-4cd161833ad3",
   "metadata": {},
   "source": [
    "**–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –±–µ–∑ –∫–æ–Ω–≤–µ–π–µ—Ä–∞**\n",
    "\n",
    "–£—Ç–µ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö (data leakage)\n",
    "–ï—Å–ª–∏ —Å–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –í–°–ï –¥–∞–Ω–Ω—ã–µ, –∞ –ø–æ—Ç–æ–º —Ä–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞ –æ–±—É—á–∞—é—â—É—é/—Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏, –º–æ–¥–µ–ª—å \"—É–∑–Ω–∞–µ—Ç\" –æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∑–∞—Ä–∞–Ω–µ–µ:\n",
    "\n",
    "```python\n",
    "# ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û: —É—Ç–µ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "scaler = StandardScaler()\n",
    "X_all_scaled = scaler.fit_transform(X_all)  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ\n",
    "X_train, X_test = train_test_split(X_all_scaled)  # –ü–æ—Ç–æ–º –¥–µ–ª–∏–º\n",
    "\n",
    "# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û: —Å–Ω–∞—á–∞–ª–∞ –¥–µ–ª–∏–º, –ø–æ—Ç–æ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º\n",
    "X_train, X_test = train_test_split(X_all)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # –¢–æ–ª—å–∫–æ –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö!\n",
    "X_test_scaled = scaler.transform(X_test)        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å –æ–±—É—á–µ–Ω–∏—è\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af6382-5238-455b-ac65-e4f925fa0b36",
   "metadata": {},
   "source": [
    "**–†–∞–∑–±–∏–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –≤—ã–±–æ—Ä–∫–∏**\n",
    "\n",
    "–¢—Ä–∏ —Ç–∏–ø–∞ –≤—ã–±–æ—Ä–æ–∫:\n",
    "- –û–±—É—á–∞—é—â–∞—è ‚Äî –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏\n",
    "- –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è ‚Äî –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "- –¢–µ—Å—Ç–æ–≤–∞—è ‚Äî –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('Response', axis=1),  # –ü—Ä–∏–∑–Ω–∞–∫–∏ (–±–µ–∑ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π)\n",
    "    data['Response'],               # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è\n",
    "    test_size=0.3,                  # 30% –≤ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É\n",
    "    stratify=data['Response'],      # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ –∫–ª–∞—Å—Å–æ–≤\n",
    "    random_state=42                 # –î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b596ebed-1688-48cd-863d-6cea0f7c693a",
   "metadata": {},
   "source": [
    "**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã vs –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã**\n",
    "\n",
    "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã ‚Äî —Ç–æ, —á—Ç–æ –º–æ–¥–µ–ª—å \"—É—á–∏—Ç\" —Å–∞–º–∞:  \n",
    "üìä –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤  \n",
    "üìà –†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –≤ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏  \n",
    "üå≥ –ü—Ä–∞–≤–∏–ª–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è –≤ –¥–µ—Ä–µ–≤–µ —Ä–µ—à–µ–Ω–∏–π\n",
    "\n",
    "–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã ‚Äî —Ç–æ, —á—Ç–æ –∑–∞–¥–∞–µ–º –ú–´:  \n",
    "üî¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Å–µ–¥–µ–π –≤ KNN (k=5)  \n",
    "üí™ –°–∏–ª–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ –≤ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ (C=10)  \n",
    "üéØ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞ (max_depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb83e7-21e2-407a-8ec5-69a82b584d39",
   "metadata": {},
   "source": [
    "**–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö**\n",
    "\n",
    "–ó–∞—á–µ–º –Ω—É–∂–Ω–∞? –ß—Ç–æ–±—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –±—ã–ª–∏ –≤ –æ–¥–Ω–æ–º –º–∞—Å—à—Ç–∞–±–µ:\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º scaler –¢–û–õ–¨–ö–û –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º –∫ –æ–±–µ–∏–º –≤—ã–±–æ—Ä–∫–∞–º\n",
    "X_train_scaled = scaler.transform(X_train)  # –û–±—É—á–∞—é—â–∞—è\n",
    "X_test_scaled = scaler.transform(X_test)    # –¢–µ—Å—Ç–æ–≤–∞—è (—Ç–µ –∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã!)\n",
    "```\n",
    "\n",
    "–§–æ—Ä–º—É–ª–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏:\n",
    "\n",
    "```text\n",
    "x_—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π = (x - —Å—Ä–µ–¥–Ω–µ–µ) / —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ_–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248819f0-627b-47da-ac20-7a66a9d37ced",
   "metadata": {},
   "source": [
    "**–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏**\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=200)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ\n",
    "train_score = model.score(X_train_scaled, y_train)\n",
    "test_score = model.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"–ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏: {train_score:.3f}\")\n",
    "print(f\"–ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ç–µ—Å—Ç–µ: {test_score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
